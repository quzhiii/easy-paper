# Vercel éƒ¨ç½²æŒ‡å— | Vercel Deployment Guide

[ä¸­æ–‡](#ä¸­æ–‡) | [English](#english)

---

## <a id="ä¸­æ–‡"></a>ğŸš€ ä¸­æ–‡ç‰ˆ

### é—®é¢˜è¯´æ˜

SciNavi AIä½¿ç”¨æµè§ˆå™¨ç›´æ¥è°ƒç”¨LLM APIï¼Œä½†éƒ¨åˆ†æœåŠ¡å•†ï¼ˆå¦‚Geminiï¼‰å­˜åœ¨CORSï¼ˆè·¨åŸŸèµ„æºå…±äº«ï¼‰é™åˆ¶ï¼Œå¯¼è‡´åœ¨Vercelç­‰å¹³å°éƒ¨ç½²åæ— æ³•æ­£å¸¸å·¥ä½œã€‚

### è§£å†³æ–¹æ¡ˆ

æœ¬é¡¹ç›®å·²é›†æˆ **Vercel Serverless Functions** ä½œä¸ºAPIä»£ç†ï¼Œè‡ªåŠ¨ç»•è¿‡CORSé™åˆ¶ã€‚

---

### ğŸ“¦ å¿«é€Ÿéƒ¨ç½²æ­¥éª¤

#### 1. å®‰è£…ä¾èµ–

```bash
npm install
```

æ–°å¢çš„ä¾èµ–ï¼š
- `@vercel/node` - Vercel Serverless Functionsç±»å‹å®šä¹‰

#### 2. éƒ¨ç½²åˆ°Vercel

**æ–¹å¼Aï¼šé€šè¿‡GitHubè‡ªåŠ¨éƒ¨ç½²ï¼ˆæ¨èï¼‰**

1. å°†ä»£ç æ¨é€åˆ°GitHubä»“åº“
2. è®¿é—® https://vercel.com
3. ç‚¹å‡» "Import Project"
4. é€‰æ‹©ä½ çš„GitHubä»“åº“
5. Vercelä¼šè‡ªåŠ¨æ£€æµ‹Viteé¡¹ç›®å¹¶é…ç½®æ„å»ºè®¾ç½®
6. ç‚¹å‡» "Deploy"

**æ–¹å¼Bï¼šä½¿ç”¨Vercel CLI**

```bash
# å®‰è£…Vercel CLI
npm i -g vercel

# ç™»å½•Vercel
vercel login

# éƒ¨ç½²
vercel --prod
```

#### 3. é…ç½®è¯´æ˜

é¡¹ç›®å·²åŒ…å«ä»¥ä¸‹é…ç½®æ–‡ä»¶ï¼š

**`vercel.json`** - Vercelå¹³å°é…ç½®
```json
{
  "rewrites": [
    {
      "source": "/api/:path*",
      "destination": "/api/:path*"
    }
  ],
  "headers": [...]
}
```

**`api/llm-proxy.ts`** - Serverless Functionä»£ç†
- è‡ªåŠ¨å¤„ç†æ‰€æœ‰LLM APIè¯·æ±‚
- æ”¯æŒQwenã€Kimiã€DeepSeekã€Zhipuã€OpenAIã€Gemini
- æ— éœ€é¢å¤–é…ç½®

---

### ğŸ”§ å·¥ä½œåŸç†

#### å¼€å‘ç¯å¢ƒï¼ˆlocalhostï¼‰
```
æµè§ˆå™¨ â†’ ç›´æ¥è°ƒç”¨ â†’ LLM API
```

#### ç”Ÿäº§ç¯å¢ƒï¼ˆVercelï¼‰
```
æµè§ˆå™¨ â†’ /api/llm-proxy â†’ Vercel Serverless Function â†’ LLM API
```

ä»£ç ä¼šè‡ªåŠ¨æ£€æµ‹ç¯å¢ƒå¹¶é€‰æ‹©åˆé€‚çš„è°ƒç”¨æ–¹å¼ï¼š
- **Gemini**: å§‹ç»ˆä½¿ç”¨ä»£ç†ï¼ˆCORSé™åˆ¶ï¼‰
- **å…¶ä»–æœåŠ¡å•†**: ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ä»£ç†ï¼Œå¼€å‘ç¯å¢ƒç›´æ¥è°ƒç”¨

---

### âœ… éªŒè¯éƒ¨ç½²

éƒ¨ç½²å®Œæˆåï¼š

1. è®¿é—®æ‚¨çš„VercelåŸŸåï¼ˆå¦‚ `https://your-app.vercel.app`ï¼‰
2. ç‚¹å‡»å³ä¸Šè§’ "API Key" æŒ‰é’®
3. é€‰æ‹©ä»»æ„æœåŠ¡å•†ï¼ˆæ¨èï¼šQwenã€Kimiã€DeepSeekï¼‰
4. è¾“å…¥API Key
5. æµ‹è¯•è¯„ä¼°åŠŸèƒ½

å¦‚æœä»ç„¶é‡åˆ°é”™è¯¯ï¼š
1. æ£€æŸ¥æµè§ˆå™¨æ§åˆ¶å°ï¼ˆF12ï¼‰
2. æŸ¥çœ‹ [TROUBLESHOOTING.md](TROUBLESHOOTING.md)
3. åœ¨GitHubæIssue

---

### ğŸŒ æ¨èæœåŠ¡å•†é…ç½®

| æœåŠ¡å•† | ä¼˜ç‚¹ | è·å–API Key |
|--------|------|------------|
| **é€šä¹‰åƒé—® (Qwen)** | é˜¿é‡Œäº‘ï¼Œå›½å†…æœ€ç¨³å®š | https://dashscope.aliyun.com/ |
| **Kimi** | æœˆä¹‹æš—é¢ï¼Œç”¨æˆ·ä½“éªŒå¥½ | https://platform.moonshot.cn/ |
| **DeepSeek** | æ·±åº¦æ±‚ç´¢ï¼Œæ€§ä»·æ¯”é«˜ | https://platform.deepseek.com/ |
| **æ™ºè°± GLM** | æ¸…åç³»ï¼ŒåŠŸèƒ½ä¸°å¯Œ | https://open.bigmodel.cn/ |
| OpenAI | GPTç³»åˆ—ï¼Œæ•ˆæœæœ€å¥½ | https://platform.openai.com/ |
| Gemini | Googleï¼Œéœ€ä»£ç† | https://ai.google.dev/ |

---

### ğŸ“ ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰

å¦‚éœ€åœ¨Vercel Dashboardé…ç½®ç¯å¢ƒå˜é‡ï¼š

1. è¿›å…¥é¡¹ç›®è®¾ç½® â†’ Environment Variables
2. æ·»åŠ å˜é‡ï¼ˆå¦‚æœéœ€è¦æœåŠ¡ç«¯ç»Ÿä¸€é…ç½®API Keyï¼‰:

```
QWEN_API_KEY=sk-xxx
KIMI_API_KEY=sk-xxx
DEEPSEEK_API_KEY=sk-xxx
```

**æ³¨æ„**ï¼šå½“å‰ç‰ˆæœ¬ä½¿ç”¨å®¢æˆ·ç«¯å­˜å‚¨API Keyï¼Œæ— éœ€æœåŠ¡ç«¯ç¯å¢ƒå˜é‡ã€‚

---

### ğŸ› å¸¸è§éƒ¨ç½²é—®é¢˜

#### é—®é¢˜1ï¼šéƒ¨ç½²åå‡ºç°404é”™è¯¯
**è§£å†³**ï¼šç¡®ä¿ `vercel.json` æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®

#### é—®é¢˜2ï¼šAPIä»£ç†ä¸å·¥ä½œ
**è§£å†³**ï¼š
1. æ£€æŸ¥ `api/llm-proxy.ts` æ–‡ä»¶æ˜¯å¦å­˜åœ¨
2. æŸ¥çœ‹Vercel Functionsæ—¥å¿—ï¼šDashboard â†’ Deployments â†’ é€‰æ‹©éƒ¨ç½² â†’ Functions

#### é—®é¢˜3ï¼šæ„å»ºå¤±è´¥
**è§£å†³**ï¼š
```bash
# æœ¬åœ°æµ‹è¯•æ„å»º
npm run build

# å¦‚æœæˆåŠŸï¼Œåˆ é™¤ .vercel æ–‡ä»¶å¤¹é‡æ–°éƒ¨ç½²
rm -rf .vercel
vercel --prod
```

---

### ğŸ“š æ›´å¤šèµ„æº

- **Vercelæ–‡æ¡£**: https://vercel.com/docs
- **Serverless Functions**: https://vercel.com/docs/functions/serverless-functions
- **é¡¹ç›®ä»“åº“**: https://github.com/quzhiii/easy-paper

---

---

## <a id="english"></a>ğŸš€ English Version

### Problem Description

SciNavi AI calls LLM APIs directly from the browser, but some providers (like Gemini) have CORS (Cross-Origin Resource Sharing) restrictions that prevent the app from working when deployed on platforms like Vercel.

### Solution

This project integrates **Vercel Serverless Functions** as an API proxy to automatically bypass CORS restrictions.

---

### ğŸ“¦ Quick Deployment Steps

#### 1. Install Dependencies

```bash
npm install
```

New dependency:
- `@vercel/node` - Type definitions for Vercel Serverless Functions

#### 2. Deploy to Vercel

**Method A: GitHub Auto-Deployment (Recommended)**

1. Push code to GitHub repository
2. Visit https://vercel.com
3. Click "Import Project"
4. Select your GitHub repository
5. Vercel will auto-detect Vite project and configure build settings
6. Click "Deploy"

**Method B: Using Vercel CLI**

```bash
# Install Vercel CLI
npm i -g vercel

# Login to Vercel
vercel login

# Deploy
vercel --prod
```

#### 3. Configuration

The project includes these configuration files:

**`vercel.json`** - Vercel platform configuration
```json
{
  "rewrites": [
    {
      "source": "/api/:path*",
      "destination": "/api/:path*"
    }
  ],
  "headers": [...]
}
```

**`api/llm-proxy.ts`** - Serverless Function proxy
- Automatically handles all LLM API requests
- Supports Qwen, Kimi, DeepSeek, Zhipu, OpenAI, Gemini
- No additional configuration needed

---

### ğŸ”§ How It Works

#### Development Environment (localhost)
```
Browser â†’ Direct Call â†’ LLM API
```

#### Production Environment (Vercel)
```
Browser â†’ /api/llm-proxy â†’ Vercel Serverless Function â†’ LLM API
```

The code automatically detects the environment and chooses the appropriate method:
- **Gemini**: Always uses proxy (CORS restriction)
- **Other Providers**: Uses proxy in production, direct call in development

---

### âœ… Verify Deployment

After deployment:

1. Visit your Vercel domain (e.g., `https://your-app.vercel.app`)
2. Click "API Key" button in top-right corner
3. Select any provider (Recommended: Qwen, Kimi, DeepSeek)
4. Enter API Key
5. Test the evaluation function

If you still encounter errors:
1. Check browser console (F12)
2. Review [TROUBLESHOOTING.md](TROUBLESHOOTING.md)
3. Submit an Issue on GitHub

---

### ğŸŒ Recommended Provider Configuration

| Provider | Advantages | Get API Key |
|----------|-----------|-------------|
| **Qwen** | Alibaba Cloud, most stable in China | https://dashscope.aliyun.com/ |
| **Kimi** | Moonshot AI, great UX | https://platform.moonshot.cn/ |
| **DeepSeek** | Cost-effective | https://platform.deepseek.com/ |
| **Zhipu GLM** | Tsinghua, feature-rich | https://open.bigmodel.cn/ |
| OpenAI | GPT series, best quality | https://platform.openai.com/ |
| Gemini | Google, requires proxy | https://ai.google.dev/ |

---

### ğŸ“ Environment Variables (Optional)

To configure environment variables in Vercel Dashboard:

1. Go to Project Settings â†’ Environment Variables
2. Add variables (if you want server-side API key configuration):

```
QWEN_API_KEY=sk-xxx
KIMI_API_KEY=sk-xxx
DEEPSEEK_API_KEY=sk-xxx
```

**Note**: Current version uses client-side API key storage, server-side env vars not required.

---

### ğŸ› Common Deployment Issues

#### Issue 1: 404 Error After Deployment
**Solution**: Ensure `vercel.json` exists and is properly formatted

#### Issue 2: API Proxy Not Working
**Solution**:
1. Check if `api/llm-proxy.ts` file exists
2. View Vercel Functions logs: Dashboard â†’ Deployments â†’ Select deployment â†’ Functions

#### Issue 3: Build Failed
**Solution**:
```bash
# Test build locally
npm run build

# If successful, delete .vercel folder and redeploy
rm -rf .vercel
vercel --prod
```

---

### ğŸ“š More Resources

- **Vercel Docs**: https://vercel.com/docs
- **Serverless Functions**: https://vercel.com/docs/functions/serverless-functions
- **Project Repository**: https://github.com/quzhiii/easy-paper

---

<div align="center">

**Happy Deploying! ğŸ‰**

</div>
